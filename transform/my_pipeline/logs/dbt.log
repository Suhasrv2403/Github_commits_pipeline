[0m12:13:45.794528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10578a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057e9310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057f9850>]}


============================== 12:13:45.798400 | c6ac2481-b261-48e9-9619-56eb122ad1f7 ==============================
[0m12:13:45.798400 [info ] [MainThread]: Running with dbt=1.11.2
[0m12:13:45.798730 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/logs', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'empty': 'None', 'introspect': 'True', 'log_format': 'default', 'version_check': 'True', 'debug': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'warn_error': 'None', 'fail_fast': 'False', 'no_print': 'None', 'profiles_dir': '/Users/suhasrvittal/.dbt', 'partial_parse': 'True', 'use_colors': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m12:13:45.810724 [info ] [MainThread]: dbt version: 1.11.2
[0m12:13:45.810940 [info ] [MainThread]: python version: 3.11.5
[0m12:13:45.811089 [info ] [MainThread]: python path: /Users/suhasrvittal/PycharmProjects/Practise/transform/venv/bin/python3.11
[0m12:13:45.811212 [info ] [MainThread]: os info: macOS-15.6.1-arm64-arm-64bit
[0m12:13:46.051971 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m12:13:46.052239 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m12:13:46.052374 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m12:13:46.078342 [info ] [MainThread]: Using profiles dir at /Users/suhasrvittal/.dbt
[0m12:13:46.078537 [info ] [MainThread]: Using profiles.yml file at /Users/suhasrvittal/.dbt/profiles.yml
[0m12:13:46.078668 [info ] [MainThread]: Using dbt_project.yml file at /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/dbt_project.yml
[0m12:13:46.078987 [info ] [MainThread]: adapter type: snowflake
[0m12:13:46.079113 [info ] [MainThread]: adapter version: 1.11.1
[0m12:13:46.121719 [info ] [MainThread]: Configuration:
[0m12:13:46.121943 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:13:46.122054 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:13:46.122153 [info ] [MainThread]: Required dependencies:
[0m12:13:46.122281 [debug] [MainThread]: Executing "git --help"
[0m12:13:46.165260 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:13:46.166037 [debug] [MainThread]: STDERR: "b''"
[0m12:13:46.166371 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:13:46.166701 [info ] [MainThread]: Connection:
[0m12:13:46.167040 [info ] [MainThread]:   account: ZQNIOQY-IIC20270
[0m12:13:46.167217 [info ] [MainThread]:   user: SRV2403
[0m12:13:46.167456 [info ] [MainThread]:   database: DE_SPEEDRUN
[0m12:13:46.167678 [info ] [MainThread]:   warehouse: COMPUTE_WH
[0m12:13:46.167810 [info ] [MainThread]:   role: ACCOUNTADMIN
[0m12:13:46.167943 [info ] [MainThread]:   schema: ANALYTICS
[0m12:13:46.168122 [info ] [MainThread]:   authenticator: None
[0m12:13:46.168240 [info ] [MainThread]:   oauth_client_id: None
[0m12:13:46.168347 [info ] [MainThread]:   query_tag: None
[0m12:13:46.168454 [info ] [MainThread]:   client_session_keep_alive: False
[0m12:13:46.168564 [info ] [MainThread]:   host: None
[0m12:13:46.168664 [info ] [MainThread]:   port: None
[0m12:13:46.168764 [info ] [MainThread]:   proxy_host: None
[0m12:13:46.168870 [info ] [MainThread]:   proxy_port: None
[0m12:13:46.168968 [info ] [MainThread]:   protocol: None
[0m12:13:46.169069 [info ] [MainThread]:   connect_retries: 1
[0m12:13:46.169163 [info ] [MainThread]:   connect_timeout: None
[0m12:13:46.169264 [info ] [MainThread]:   retry_on_database_errors: False
[0m12:13:46.169361 [info ] [MainThread]:   retry_all: False
[0m12:13:46.169454 [info ] [MainThread]:   insecure_mode: False
[0m12:13:46.169548 [info ] [MainThread]:   reuse_connections: True
[0m12:13:46.169641 [info ] [MainThread]:   s3_stage_vpce_dns_name: None
[0m12:13:46.169747 [info ] [MainThread]:   platform_detection_timeout_seconds: 0.0
[0m12:13:46.170032 [info ] [MainThread]: Registered adapter: snowflake=1.11.1
[0m12:13:46.232454 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m12:13:46.259347 [debug] [MainThread]: Using snowflake connection "debug"
[0m12:13:46.259541 [debug] [MainThread]: On debug: select 1 as id
[0m12:13:46.259668 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:13:47.190020 [debug] [MainThread]: SQL status: SUCCESS 1 in 0.930 seconds
[0m12:13:47.192497 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:13:47.193225 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:13:47.199399 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.4484302, "process_in_blocks": "0", "process_kernel_time": 0.270412, "process_mem_max_rss": "147193856", "process_out_blocks": "0", "process_user_time": 0.981278}
[0m12:13:47.200449 [debug] [MainThread]: Command `dbt debug` succeeded at 12:13:47.200210 after 1.45 seconds
[0m12:13:47.200946 [debug] [MainThread]: Connection 'debug' was left open.
[0m12:13:47.201289 [debug] [MainThread]: On debug: Close
[0m12:13:47.405885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ed8790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ae08d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a53c50>]}
[0m12:13:47.407266 [debug] [MainThread]: Flushing usage events
[0m12:13:48.494302 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:16:02.941159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107711c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107775e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778e490>]}


============================== 12:16:02.944413 | 2ebe888f-0016-471b-88c1-06b4f851bbf7 ==============================
[0m12:16:02.944413 [info ] [MainThread]: Running with dbt=1.11.2
[0m12:16:02.944739 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'write_json': 'True', 'quiet': 'False', 'version_check': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'printer_width': '80', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'log_path': '/Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/logs', 'indirect_selection': 'eager', 'invocation_command': 'dbt run', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'no_print': 'None', 'profiles_dir': '/Users/suhasrvittal/.dbt', 'warn_error': 'None'}
[0m12:16:03.180811 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m12:16:03.181081 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m12:16:03.181223 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m12:16:03.267621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10857b5d0>]}
[0m12:16:03.294278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068dcf10>]}
[0m12:16:03.294874 [info ] [MainThread]: Registered adapter: snowflake=1.11.1
[0m12:16:03.361052 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m12:16:03.361621 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:16:03.361880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b3190>]}
[0m12:16:03.987717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089e5290>]}
[0m12:16:04.026884 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:16:04.028050 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:16:04.039043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108952f50>]}
[0m12:16:04.039288 [info ] [MainThread]: Found 3 models, 4 data tests, 1 source, 522 macros
[0m12:16:04.039455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097194d0>]}
[0m12:16:04.040264 [info ] [MainThread]: 
[0m12:16:04.040415 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:16:04.040530 [info ] [MainThread]: 
[0m12:16:04.040721 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:16:04.042665 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m12:16:04.070186 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m12:16:04.070356 [debug] [ThreadPool]: On list_DE_SPEEDRUN: show terse schemas in database DE_SPEEDRUN
    limit 10000
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
[0m12:16:04.070473 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:16:04.893044 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.822 seconds
[0m12:16:04.897077 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN, now create_DE_SPEEDRUN_ANALYTICS)
[0m12:16:04.898041 [debug] [ThreadPool]: Creating schema "database: "DE_SPEEDRUN"
schema: "ANALYTICS"
"
[0m12:16:04.904410 [debug] [ThreadPool]: Using snowflake connection "create_DE_SPEEDRUN_ANALYTICS"
[0m12:16:04.904765 [debug] [ThreadPool]: On create_DE_SPEEDRUN_ANALYTICS: create schema if not exists DE_SPEEDRUN.ANALYTICS
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "create_DE_SPEEDRUN_ANALYTICS"} */
[0m12:16:05.113921 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.209 seconds
[0m12:16:05.117028 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_DE_SPEEDRUN_ANALYTICS, now list_DE_SPEEDRUN_ANALYTICS)
[0m12:16:05.133246 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m12:16:05.133702 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: show objects in DE_SPEEDRUN.ANALYTICS
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */;
[0m12:16:05.287536 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.153 seconds
[0m12:16:05.290205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10899bdd0>]}
[0m12:16:05.295028 [debug] [Thread-2 (]: Began running node model.my_pipeline.my_first_dbt_model
[0m12:16:05.296439 [info ] [Thread-2 (]: 1 of 3 START sql table model ANALYTICS.my_first_dbt_model ...................... [RUN]
[0m12:16:05.297165 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.my_first_dbt_model)
[0m12:16:05.297575 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.my_first_dbt_model
[0m12:16:05.308042 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.my_first_dbt_model"
[0m12:16:05.309047 [debug] [Thread-2 (]: Began executing node model.my_pipeline.my_first_dbt_model
[0m12:16:05.329288 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.my_first_dbt_model"
[0m12:16:05.330336 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.my_first_dbt_model"
[0m12:16:05.330568 [debug] [Thread-2 (]: On model.my_pipeline.my_first_dbt_model: create or replace transient table DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
    
    
    
    as (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    )

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.my_first_dbt_model"} */;
[0m12:16:06.749444 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.418 seconds
[0m12:16:06.778428 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089ab650>]}
[0m12:16:06.779140 [info ] [Thread-2 (]: 1 of 3 OK created sql table model ANALYTICS.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 1.48s]
[0m12:16:06.779586 [debug] [Thread-2 (]: Finished running node model.my_pipeline.my_first_dbt_model
[0m12:16:06.779880 [debug] [Thread-2 (]: Began running node model.my_pipeline.stg_commits
[0m12:16:06.780211 [info ] [Thread-2 (]: 2 of 3 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m12:16:06.780735 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.my_pipeline.my_first_dbt_model, now model.my_pipeline.stg_commits)
[0m12:16:06.780979 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.stg_commits
[0m12:16:06.783656 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m12:16:06.784266 [debug] [Thread-2 (]: Began executing node model.my_pipeline.stg_commits
[0m12:16:06.798470 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m12:16:06.799380 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m12:16:06.799631 [debug] [Thread-2 (]: On model.my_pipeline.stg_commits: create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
  
  
  
  as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  )
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */;
[0m12:16:07.102661 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.302 seconds
[0m12:16:07.107306 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108568f90>]}
[0m12:16:07.108290 [info ] [Thread-2 (]: 2 of 3 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 0.33s]
[0m12:16:07.108974 [debug] [Thread-2 (]: Finished running node model.my_pipeline.stg_commits
[0m12:16:07.109454 [debug] [Thread-2 (]: Began running node model.my_pipeline.my_second_dbt_model
[0m12:16:07.110112 [info ] [Thread-2 (]: 3 of 3 START sql view model ANALYTICS.my_second_dbt_model ...................... [RUN]
[0m12:16:07.110723 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.my_second_dbt_model)
[0m12:16:07.111148 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.my_second_dbt_model
[0m12:16:07.114894 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.my_second_dbt_model"
[0m12:16:07.115720 [debug] [Thread-2 (]: Began executing node model.my_pipeline.my_second_dbt_model
[0m12:16:07.118786 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.my_second_dbt_model"
[0m12:16:07.119581 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.my_second_dbt_model"
[0m12:16:07.119883 [debug] [Thread-2 (]: On model.my_pipeline.my_second_dbt_model: create or replace   view DE_SPEEDRUN.ANALYTICS.my_second_dbt_model
  
  
  
  
  as (
    -- Use the `ref` function to select from other models

select *
from DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
where id = 1
  )
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.my_second_dbt_model"} */;
[0m12:16:07.452149 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.332 seconds
[0m12:16:07.456842 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ebe888f-0016-471b-88c1-06b4f851bbf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10999ca50>]}
[0m12:16:07.457835 [info ] [Thread-2 (]: 3 of 3 OK created sql view model ANALYTICS.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.35s]
[0m12:16:07.458631 [debug] [Thread-2 (]: Finished running node model.my_pipeline.my_second_dbt_model
[0m12:16:07.460589 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:16:07.461097 [debug] [MainThread]: Connection 'model.my_pipeline.my_second_dbt_model' was left open.
[0m12:16:07.461458 [debug] [MainThread]: On model.my_pipeline.my_second_dbt_model: Close
[0m12:16:07.683601 [info ] [MainThread]: 
[0m12:16:07.684599 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 3.64 seconds (3.64s).
[0m12:16:07.685893 [debug] [MainThread]: Command end result
[0m12:16:07.707545 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:16:07.709555 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:16:07.713387 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/run_results.json
[0m12:16:07.713554 [info ] [MainThread]: 
[0m12:16:07.713746 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:16:07.713885 [info ] [MainThread]: 
[0m12:16:07.714054 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m12:16:07.717596 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8236456, "process_in_blocks": "0", "process_kernel_time": 0.265117, "process_mem_max_rss": "159186944", "process_out_blocks": "0", "process_user_time": 1.750919}
[0m12:16:07.718208 [debug] [MainThread]: Command `dbt run` succeeded at 12:16:07.718155 after 4.82 seconds
[0m12:16:07.718504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c58750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107793f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107793f90>]}
[0m12:16:07.718695 [debug] [MainThread]: Flushing usage events
[0m12:16:08.103444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:19:20.585455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072eac10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10734e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107366b90>]}


============================== 12:19:20.588679 | bc96864e-2e7b-4ca0-91c3-da7fcfaba567 ==============================
[0m12:19:20.588679 [info ] [MainThread]: Running with dbt=1.11.2
[0m12:19:20.589042 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'warn_error': 'None', 'debug': 'False', 'printer_width': '80', 'introspect': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'invocation_command': 'dbt run', 'target_path': 'None', 'empty': 'False', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'log_path': '/Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/logs', 'use_colors': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/suhasrvittal/.dbt', 'write_json': 'True'}
[0m12:19:20.817315 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m12:19:20.817585 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m12:19:20.817728 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m12:19:20.904348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086b9590>]}
[0m12:19:20.929353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b41d0>]}
[0m12:19:20.929889 [info ] [MainThread]: Registered adapter: snowflake=1.11.1
[0m12:19:20.994763 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m12:19:21.077823 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:19:21.078070 [debug] [MainThread]: Partial parsing: added file: my_pipeline://models/fact_commits.sql
[0m12:19:21.192223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972aa90>]}
[0m12:19:21.231624 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:19:21.233469 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:19:21.245134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098b0dd0>]}
[0m12:19:21.245361 [info ] [MainThread]: Found 4 models, 4 data tests, 1 source, 522 macros
[0m12:19:21.245503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10971f950>]}
[0m12:19:21.246374 [info ] [MainThread]: 
[0m12:19:21.246528 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:19:21.246641 [info ] [MainThread]: 
[0m12:19:21.246841 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:19:21.248815 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m12:19:21.283346 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m12:19:21.283559 [debug] [ThreadPool]: On list_DE_SPEEDRUN: show terse schemas in database DE_SPEEDRUN
    limit 10000
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
[0m12:19:21.283683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:19:22.101081 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.817 seconds
[0m12:19:22.106037 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN, now list_DE_SPEEDRUN_ANALYTICS)
[0m12:19:22.124832 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m12:19:22.125682 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: show objects in DE_SPEEDRUN.ANALYTICS
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */;
[0m12:19:22.272440 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 0.146 seconds
[0m12:19:22.275191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085a2010>]}
[0m12:19:22.278701 [debug] [Thread-2 (]: Began running node model.my_pipeline.my_first_dbt_model
[0m12:19:22.279545 [info ] [Thread-2 (]: 1 of 4 START sql table model ANALYTICS.my_first_dbt_model ...................... [RUN]
[0m12:19:22.280215 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.my_first_dbt_model)
[0m12:19:22.280647 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.my_first_dbt_model
[0m12:19:22.288276 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.my_first_dbt_model"
[0m12:19:22.289188 [debug] [Thread-2 (]: Began executing node model.my_pipeline.my_first_dbt_model
[0m12:19:22.312428 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.my_first_dbt_model"
[0m12:19:22.313253 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.my_first_dbt_model"
[0m12:19:22.313519 [debug] [Thread-2 (]: On model.my_pipeline.my_first_dbt_model: create or replace transient table DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
    
    
    
    as (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    )

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.my_first_dbt_model"} */;
[0m12:19:23.027865 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.714 seconds
[0m12:19:23.056781 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099afd90>]}
[0m12:19:23.057411 [info ] [Thread-2 (]: 1 of 4 OK created sql table model ANALYTICS.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 0.78s]
[0m12:19:23.057829 [debug] [Thread-2 (]: Finished running node model.my_pipeline.my_first_dbt_model
[0m12:19:23.058119 [debug] [Thread-2 (]: Began running node model.my_pipeline.stg_commits
[0m12:19:23.058531 [info ] [Thread-2 (]: 2 of 4 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m12:19:23.058968 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.my_pipeline.my_first_dbt_model, now model.my_pipeline.stg_commits)
[0m12:19:23.059245 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.stg_commits
[0m12:19:23.061655 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m12:19:23.062156 [debug] [Thread-2 (]: Began executing node model.my_pipeline.stg_commits
[0m12:19:23.077650 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m12:19:23.078501 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m12:19:23.078729 [debug] [Thread-2 (]: On model.my_pipeline.stg_commits: create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
  
  
  
  as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  )
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */;
[0m12:19:23.589978 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.511 seconds
[0m12:19:23.593266 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a522f90>]}
[0m12:19:23.593959 [info ] [Thread-2 (]: 2 of 4 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 0.53s]
[0m12:19:23.594591 [debug] [Thread-2 (]: Finished running node model.my_pipeline.stg_commits
[0m12:19:23.595060 [debug] [Thread-2 (]: Began running node model.my_pipeline.my_second_dbt_model
[0m12:19:23.595783 [info ] [Thread-2 (]: 3 of 4 START sql view model ANALYTICS.my_second_dbt_model ...................... [RUN]
[0m12:19:23.596308 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.my_second_dbt_model)
[0m12:19:23.596637 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.my_second_dbt_model
[0m12:19:23.600196 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.my_second_dbt_model"
[0m12:19:23.601012 [debug] [Thread-2 (]: Began executing node model.my_pipeline.my_second_dbt_model
[0m12:19:23.603830 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.my_second_dbt_model"
[0m12:19:23.604697 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.my_second_dbt_model"
[0m12:19:23.605007 [debug] [Thread-2 (]: On model.my_pipeline.my_second_dbt_model: create or replace   view DE_SPEEDRUN.ANALYTICS.my_second_dbt_model
  
  
  
  
  as (
    -- Use the `ref` function to select from other models

select *
from DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
where id = 1
  )
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.my_second_dbt_model"} */;
[0m12:19:23.833705 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.228 seconds
[0m12:19:23.837838 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5213d0>]}
[0m12:19:23.838750 [info ] [Thread-2 (]: 3 of 4 OK created sql view model ANALYTICS.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.24s]
[0m12:19:23.839772 [debug] [Thread-2 (]: Finished running node model.my_pipeline.my_second_dbt_model
[0m12:19:23.840274 [debug] [Thread-2 (]: Began running node model.my_pipeline.fact_commits
[0m12:19:23.841008 [info ] [Thread-2 (]: 4 of 4 START sql table model ANALYTICS.fact_commits ............................ [RUN]
[0m12:19:23.841637 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.my_pipeline.my_second_dbt_model, now model.my_pipeline.fact_commits)
[0m12:19:23.842085 [debug] [Thread-2 (]: Began compiling node model.my_pipeline.fact_commits
[0m12:19:23.846264 [debug] [Thread-2 (]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m12:19:23.847011 [debug] [Thread-2 (]: Began executing node model.my_pipeline.fact_commits
[0m12:19:23.850099 [debug] [Thread-2 (]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m12:19:23.851156 [debug] [Thread-2 (]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m12:19:23.851522 [debug] [Thread-2 (]: On model.my_pipeline.fact_commits: create or replace transient table DE_SPEEDRUN.ANALYTICS.fact_commits
    
    
    
    as (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.ANALYTICS.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
    )

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */;
[0m12:19:24.913486 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 1.061 seconds
[0m12:19:24.919631 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc96864e-2e7b-4ca0-91c3-da7fcfaba567', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a516590>]}
[0m12:19:24.920742 [info ] [Thread-2 (]: 4 of 4 OK created sql table model ANALYTICS.fact_commits ....................... [[32mSUCCESS 1[0m in 1.08s]
[0m12:19:24.921782 [debug] [Thread-2 (]: Finished running node model.my_pipeline.fact_commits
[0m12:19:24.923603 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:19:24.923994 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was left open.
[0m12:19:24.924325 [debug] [MainThread]: On model.my_pipeline.fact_commits: Close
[0m12:19:25.119014 [info ] [MainThread]: 
[0m12:19:25.119785 [info ] [MainThread]: Finished running 2 table models, 2 view models in 0 hours 0 minutes and 3.87 seconds (3.87s).
[0m12:19:25.121159 [debug] [MainThread]: Command end result
[0m12:19:25.196756 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:19:25.197696 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:19:25.200500 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/run_results.json
[0m12:19:25.200637 [info ] [MainThread]: 
[0m12:19:25.200798 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:19:25.200928 [info ] [MainThread]: 
[0m12:19:25.201062 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m12:19:25.202815 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.667711, "process_in_blocks": "0", "process_kernel_time": 0.260288, "process_mem_max_rss": "159875072", "process_out_blocks": "0", "process_user_time": 1.37488}
[0m12:19:25.203026 [debug] [MainThread]: Command `dbt run` succeeded at 12:19:25.202986 after 4.67 seconds
[0m12:19:25.203189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009f4790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100a80950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100a81110>]}
[0m12:19:25.203342 [debug] [MainThread]: Flushing usage events
[0m12:19:25.606148 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:20:03.846994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107218250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107292010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107292690>]}


============================== 12:20:03.851171 | 03c18575-c2d1-4515-962f-6569cbf8fb60 ==============================
[0m12:20:03.851171 [info ] [MainThread]: Running with dbt=1.11.2
[0m12:20:03.851505 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'use_colors': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'empty': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'invocation_command': 'dbt test', 'quiet': 'False', 'introspect': 'True', 'no_print': 'None', 'profiles_dir': '/Users/suhasrvittal/.dbt', 'fail_fast': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/logs', 'partial_parse': 'True'}
[0m12:20:04.075669 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m12:20:04.075944 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m12:20:04.076084 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m12:20:04.163735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080d4e50>]}
[0m12:20:04.189316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063e4350>]}
[0m12:20:04.189894 [info ] [MainThread]: Registered adapter: snowflake=1.11.1
[0m12:20:04.262868 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m12:20:04.341758 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:20:04.342050 [debug] [MainThread]: Partial parsing: added file: my_pipeline://models/schema.yml
[0m12:20:04.453139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081b9250>]}
[0m12:20:04.493676 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:20:04.494685 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:20:04.512086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093afd10>]}
[0m12:20:04.512331 [info ] [MainThread]: Found 4 models, 7 data tests, 1 source, 522 macros
[0m12:20:04.512481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092b7050>]}
[0m12:20:04.513518 [info ] [MainThread]: 
[0m12:20:04.513680 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:20:04.513794 [info ] [MainThread]: 
[0m12:20:04.513992 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:20:04.515962 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m12:20:04.548226 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m12:20:04.548422 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: show objects in DE_SPEEDRUN.ANALYTICS
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */;
[0m12:20:04.548547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:05.366952 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.818 seconds
[0m12:20:05.371339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03c18575-c2d1-4515-962f-6569cbf8fb60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091e3250>]}
[0m12:20:05.377073 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:05.377592 [info ] [Thread-2 (]: 1 of 7 START test not_null_fact_commits_author_name ............................ [RUN]
[0m12:20:05.378065 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m12:20:05.378500 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:05.395410 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:05.396146 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:05.411605 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:05.412536 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:05.412773 [debug] [Thread-2 (]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
[0m12:20:05.744363 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.331 seconds
[0m12:20:05.756580 [info ] [Thread-2 (]: 1 of 7 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 0.38s]
[0m12:20:05.757421 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:05.757925 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:05.758504 [info ] [Thread-2 (]: 2 of 7 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m12:20:05.759164 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m12:20:05.759644 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:05.765227 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:05.765971 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:05.768751 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:05.769740 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:05.770100 [debug] [Thread-2 (]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
[0m12:20:06.209777 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.438 seconds
[0m12:20:06.214117 [info ] [Thread-2 (]: 2 of 7 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 0.45s]
[0m12:20:06.215287 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:06.216953 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710
[0m12:20:06.217584 [info ] [Thread-2 (]: 3 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m12:20:06.218873 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710)
[0m12:20:06.219603 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710
[0m12:20:06.226907 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710"
[0m12:20:06.227970 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710
[0m12:20:06.231368 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710"
[0m12:20:06.232513 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710"
[0m12:20:06.232879 [debug] [Thread-2 (]: On test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
where id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710"} */
[0m12:20:06.672312 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.439 seconds
[0m12:20:06.676726 [error] [Thread-2 (]: 3 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.46s]
[0m12:20:06.677560 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710
[0m12:20:06.678051 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778
[0m12:20:06.678526 [info ] [Thread-2 (]: 4 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m12:20:06.679002 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_my_first_dbt_model_id.5fb22c2710, now test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778)
[0m12:20:06.679395 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778
[0m12:20:06.684742 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778"
[0m12:20:06.685621 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778
[0m12:20:06.688540 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778"
[0m12:20:06.689636 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778"
[0m12:20:06.689966 [debug] [Thread-2 (]: On test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from DE_SPEEDRUN.ANALYTICS.my_second_dbt_model
where id is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778"} */
[0m12:20:06.999490 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.309 seconds
[0m12:20:07.003959 [info ] [Thread-2 (]: 4 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.32s]
[0m12:20:07.004973 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778
[0m12:20:07.005577 [debug] [Thread-2 (]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:07.006323 [info ] [Thread-2 (]: 5 of 7 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m12:20:07.007005 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_my_second_dbt_model_id.151b76d778, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m12:20:07.007472 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:07.083337 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:07.083876 [debug] [Thread-2 (]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:07.085325 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:07.085886 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:07.086062 [debug] [Thread-2 (]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
[0m12:20:07.563739 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.477 seconds
[0m12:20:07.568931 [info ] [Thread-2 (]: 5 of 7 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 0.56s]
[0m12:20:07.569871 [debug] [Thread-2 (]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:07.570334 [debug] [Thread-2 (]: Began running node test.my_pipeline.unique_my_first_dbt_model_id.16e066b321
[0m12:20:07.570809 [info ] [Thread-2 (]: 6 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m12:20:07.571346 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745, now test.my_pipeline.unique_my_first_dbt_model_id.16e066b321)
[0m12:20:07.571809 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.unique_my_first_dbt_model_id.16e066b321
[0m12:20:07.578689 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.unique_my_first_dbt_model_id.16e066b321"
[0m12:20:07.579940 [debug] [Thread-2 (]: Began executing node test.my_pipeline.unique_my_first_dbt_model_id.16e066b321
[0m12:20:07.585854 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.unique_my_first_dbt_model_id.16e066b321"
[0m12:20:07.587865 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.unique_my_first_dbt_model_id.16e066b321"
[0m12:20:07.588426 [debug] [Thread-2 (]: On test.my_pipeline.unique_my_first_dbt_model_id.16e066b321: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.my_first_dbt_model
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_my_first_dbt_model_id.16e066b321"} */
[0m12:20:08.372183 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.783 seconds
[0m12:20:08.375470 [info ] [Thread-2 (]: 6 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.80s]
[0m12:20:08.376274 [debug] [Thread-2 (]: Finished running node test.my_pipeline.unique_my_first_dbt_model_id.16e066b321
[0m12:20:08.377146 [debug] [Thread-2 (]: Began running node test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493
[0m12:20:08.377819 [info ] [Thread-2 (]: 7 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m12:20:08.378533 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.unique_my_first_dbt_model_id.16e066b321, now test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493)
[0m12:20:08.379248 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493
[0m12:20:08.384044 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493"
[0m12:20:08.384506 [debug] [Thread-2 (]: Began executing node test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493
[0m12:20:08.386043 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493"
[0m12:20:08.386649 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493"
[0m12:20:08.386830 [debug] [Thread-2 (]: On test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493"} */
[0m12:20:08.583979 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.197 seconds
[0m12:20:08.587396 [info ] [Thread-2 (]: 7 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.21s]
[0m12:20:08.588259 [debug] [Thread-2 (]: Finished running node test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493
[0m12:20:08.590368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:08.590866 [debug] [MainThread]: Connection 'test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493' was left open.
[0m12:20:08.591273 [debug] [MainThread]: On test.my_pipeline.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m12:20:08.803080 [info ] [MainThread]: 
[0m12:20:08.803765 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m12:20:08.805450 [debug] [MainThread]: Command end result
[0m12:20:08.824200 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:20:08.826085 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:20:08.829663 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/run_results.json
[0m12:20:08.829820 [info ] [MainThread]: 
[0m12:20:08.830008 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:20:08.830139 [info ] [MainThread]: 
[0m12:20:08.830315 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m12:20:08.830455 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m12:20:08.830558 [info ] [MainThread]: 
[0m12:20:08.830691 [info ] [MainThread]:   compiled code at target/compiled/my_pipeline/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m12:20:08.830813 [info ] [MainThread]: 
[0m12:20:08.833873 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=7
[0m12:20:08.835900 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 5.041193, "process_in_blocks": "0", "process_kernel_time": 0.279295, "process_mem_max_rss": "157302784", "process_out_blocks": "0", "process_user_time": 1.404553}
[0m12:20:08.836172 [debug] [MainThread]: Command `dbt test` failed at 12:20:08.836129 after 5.04 seconds
[0m12:20:08.836438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728f450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c06c10>]}
[0m12:20:08.836659 [debug] [MainThread]: Flushing usage events
[0m12:20:09.613405 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:20:46.552613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10956e8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095cddd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095e6350>]}


============================== 12:20:46.555305 | 8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f ==============================
[0m12:20:46.555305 [info ] [MainThread]: Running with dbt=1.11.2
[0m12:20:46.555646 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'debug': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt test', 'profiles_dir': '/Users/suhasrvittal/.dbt', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'use_colors': 'True', 'quiet': 'False', 'log_path': '/Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/logs', 'indirect_selection': 'eager', 'target_path': 'None', 'printer_width': '80'}
[0m12:20:46.807443 [debug] [MainThread]: Snowflake adapter: Setting snowflake.connector to ERROR (file logging only)
[0m12:20:46.807702 [debug] [MainThread]: Snowflake adapter: Setting botocore to ERROR (file logging only)
[0m12:20:46.807847 [debug] [MainThread]: Snowflake adapter: Setting boto3 to ERROR (file logging only)
[0m12:20:46.893626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10956db90>]}
[0m12:20:46.918633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108738e50>]}
[0m12:20:46.919165 [info ] [MainThread]: Registered adapter: snowflake=1.11.1
[0m12:20:46.981745 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m12:20:47.060649 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
[0m12:20:47.060912 [debug] [MainThread]: Partial parsing: deleted file: my_pipeline://models/example/my_second_dbt_model.sql
[0m12:20:47.061033 [debug] [MainThread]: Partial parsing: deleted file: my_pipeline://models/example/my_first_dbt_model.sql
[0m12:20:47.094175 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m12:20:47.100297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a688a10>]}
[0m12:20:47.140162 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:20:47.141581 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:20:47.159683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4f7650>]}
[0m12:20:47.159908 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 522 macros
[0m12:20:47.160053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a687110>]}
[0m12:20:47.160935 [info ] [MainThread]: 
[0m12:20:47.161093 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:20:47.161205 [info ] [MainThread]: 
[0m12:20:47.161417 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:20:47.163353 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m12:20:47.196114 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m12:20:47.196271 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: show objects in DE_SPEEDRUN.ANALYTICS
    limit 10000
    

/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */;
[0m12:20:47.196394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:20:49.069321 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.873 seconds
[0m12:20:49.073905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a1cc0a5-3d27-4eef-ad90-b96bd0e8d81f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095c6d50>]}
[0m12:20:49.077290 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:49.077795 [info ] [Thread-2 (]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m12:20:49.078286 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m12:20:49.078980 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:49.098045 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:49.099028 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:49.115072 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:49.115828 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m12:20:49.116064 [debug] [Thread-2 (]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
[0m12:20:49.297416 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.181 seconds
[0m12:20:49.310816 [info ] [Thread-2 (]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 0.23s]
[0m12:20:49.311352 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m12:20:49.311623 [debug] [Thread-2 (]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:49.311940 [info ] [Thread-2 (]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m12:20:49.312253 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m12:20:49.312461 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:49.316673 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:49.317312 [debug] [Thread-2 (]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:49.319951 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:49.320796 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m12:20:49.321009 [debug] [Thread-2 (]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
[0m12:20:49.497223 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.176 seconds
[0m12:20:49.502309 [info ] [Thread-2 (]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 0.19s]
[0m12:20:49.503287 [debug] [Thread-2 (]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m12:20:49.503994 [debug] [Thread-2 (]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:49.504527 [info ] [Thread-2 (]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m12:20:49.505447 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m12:20:49.506048 [debug] [Thread-2 (]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:49.518847 [debug] [Thread-2 (]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:49.519926 [debug] [Thread-2 (]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:49.523246 [debug] [Thread-2 (]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:49.524193 [debug] [Thread-2 (]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m12:20:49.524499 [debug] [Thread-2 (]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



  
  
      
    ) dbt_internal_test
/* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
[0m12:20:49.792243 [debug] [Thread-2 (]: SQL status: SUCCESS 1 in 0.267 seconds
[0m12:20:49.797923 [info ] [Thread-2 (]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 0.29s]
[0m12:20:49.798858 [debug] [Thread-2 (]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m12:20:49.800722 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:20:49.801328 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was left open.
[0m12:20:49.801811 [debug] [MainThread]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m12:20:50.008235 [info ] [MainThread]: 
[0m12:20:50.009179 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 2.85 seconds (2.85s).
[0m12:20:50.010647 [debug] [MainThread]: Command end result
[0m12:20:50.041612 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/manifest.json
[0m12:20:50.042950 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/semantic_manifest.json
[0m12:20:50.047615 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/suhasrvittal/PycharmProjects/Practise/transform/my_pipeline/target/run_results.json
[0m12:20:50.047829 [info ] [MainThread]: 
[0m12:20:50.048070 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:20:50.048248 [info ] [MainThread]: 
[0m12:20:50.048445 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m12:20:50.050841 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.5394046, "process_in_blocks": "0", "process_kernel_time": 0.245597, "process_mem_max_rss": "152879104", "process_out_blocks": "0", "process_user_time": 1.212722}
[0m12:20:50.051180 [debug] [MainThread]: Command `dbt test` succeeded at 12:20:50.051133 after 3.54 seconds
[0m12:20:50.051391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b80790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095cc150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109486fd0>]}
[0m12:20:50.051608 [debug] [MainThread]: Flushing usage events
[0m12:20:50.513177 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:53:27.835075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba0623d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb75ad4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb67ad4c0>]}


============================== 22:53:27.847167 | 7b5d4a76-8c77-4de2-b72c-581324baa2d8 ==============================
[0m22:53:27.847167 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:53:27.847643 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:53:27.887465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab524430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa943c4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa923c040>]}


============================== 22:53:27.905473 | c7a5f59f-0692-4330-9867-6445eb4734f8 ==============================
[0m22:53:27.905473 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:53:27.906745 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m22:53:30.220861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb67a3e50>]}
[0m22:53:30.221079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa90bc850>]}
[0m22:53:30.300415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8776dfa0>]}
[0m22:53:30.302356 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m22:53:30.306579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb68332e0>]}
[0m22:53:30.309102 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m22:53:30.358422 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:53:30.359026 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:53:30.503663 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m22:53:30.522308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb75823a0>]}
[0m22:53:30.547277 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m22:53:30.549696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa0515b0>]}
[0m22:53:31.314285 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:53:31.314834 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m22:53:31.315425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3e00bb0>]}
[0m22:53:31.315530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6848fd0>]}
[0m22:53:31.468142 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m22:53:31.468440 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m22:53:31.479605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5bfcb50>]}
[0m22:53:31.479608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3174af0>]}
[0m22:53:31.680231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3105610>]}
[0m22:53:31.681381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5bc16a0>]}
[0m22:53:31.681582 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m22:53:31.685792 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m22:53:31.686472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb31a1dc0>]}
[0m22:53:31.688513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5c2d820>]}
[0m22:53:31.695894 [info ] [MainThread]: 
[0m22:53:31.696510 [info ] [MainThread]: 
[0m22:53:31.701898 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:53:31.702059 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:53:31.725837 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m22:53:31.726575 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m22:53:31.746175 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m22:53:31.746759 [debug] [ThreadPool]: On list_DE_SPEEDRUN: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
show terse schemas in database DE_SPEEDRUN
    limit 10000
[0m22:53:31.747143 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:31.747118 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m22:53:31.747613 [debug] [ThreadPool]: On list_DE_SPEEDRUN: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
show terse schemas in database DE_SPEEDRUN
    limit 10000
[0m22:53:31.748157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:34.878747 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3.130 seconds
[0m22:53:34.884506 [debug] [ThreadPool]: On list_DE_SPEEDRUN: Close
[0m22:53:34.976516 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 3.229 seconds
[0m22:53:34.979047 [debug] [ThreadPool]: On list_DE_SPEEDRUN: Close
[0m22:53:35.558369 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m22:53:35.579714 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m22:53:35.580372 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m22:53:35.580848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:35.873340 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN, now list_DE_SPEEDRUN_ANALYTICS)
[0m22:53:35.889563 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m22:53:35.890083 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m22:53:35.890461 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:53:36.868764 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.978 seconds
[0m22:53:36.868901 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.288 seconds
[0m22:53:36.880466 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m22:53:36.881051 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m22:53:37.123415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5ce0c10>]}
[0m22:53:37.126353 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:53:37.126992 [info ] [MainThread]: 
[0m22:53:37.144131 [debug] [Thread-1  ]: Began running node model.my_pipeline.stg_commits
[0m22:53:37.144811 [info ] [Thread-1  ]: 1 of 2 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m22:53:37.145378 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.stg_commits)
[0m22:53:37.145791 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.stg_commits
[0m22:53:37.149280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb324f670>]}
[0m22:53:37.151429 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:53:37.152014 [info ] [MainThread]: 
[0m22:53:37.160741 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m22:53:37.165948 [debug] [Thread-1  ]: Began executing node model.my_pipeline.stg_commits
[0m22:53:37.171326 [debug] [Thread-1  ]: Began running node model.my_pipeline.stg_commits
[0m22:53:37.172357 [info ] [Thread-1  ]: 1 of 2 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m22:53:37.173037 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.stg_commits)
[0m22:53:37.173416 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.stg_commits
[0m22:53:37.185542 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m22:53:37.186822 [debug] [Thread-1  ]: Began executing node model.my_pipeline.stg_commits
[0m22:53:37.196621 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m22:53:37.200113 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m22:53:37.200512 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */
create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
   as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  );
[0m22:53:37.200937 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:37.209704 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m22:53:37.210899 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m22:53:37.211295 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */
create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
   as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  );
[0m22:53:37.211599 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:37.972011 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.770 seconds
[0m22:53:38.012472 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: Close
[0m22:53:38.222071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e48fd00>]}
[0m22:53:38.225158 [info ] [Thread-1  ]: 1 of 2 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 1.07s]
[0m22:53:38.227070 [debug] [Thread-1  ]: Finished running node model.my_pipeline.stg_commits
[0m22:53:38.229366 [debug] [Thread-1  ]: Began running node model.my_pipeline.fact_commits
[0m22:53:38.230696 [info ] [Thread-1  ]: 2 of 2 START sql table model ANALYTICS.fact_commits ............................ [RUN]
[0m22:53:38.231666 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.fact_commits)
[0m22:53:38.232332 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.fact_commits
[0m22:53:38.238124 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m22:53:38.240539 [debug] [Thread-1  ]: Began executing node model.my_pipeline.fact_commits
[0m22:53:38.262263 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m22:53:38.263692 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m22:53:38.264073 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */
create or replace transient table DE_SPEEDRUN.ANALYTICS.fact_commits
         as
        (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.ANALYTICS.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
        );
[0m22:53:38.264448 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:38.294508 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.083 seconds
[0m22:53:38.314393 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: Close
[0m22:53:38.525733 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff979deca0>]}
[0m22:53:38.527048 [info ] [Thread-1  ]: 1 of 2 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 1.35s]
[0m22:53:38.528163 [debug] [Thread-1  ]: Finished running node model.my_pipeline.stg_commits
[0m22:53:38.530175 [debug] [Thread-1  ]: Began running node model.my_pipeline.fact_commits
[0m22:53:38.530904 [info ] [Thread-1  ]: 2 of 2 START sql table model ANALYTICS.fact_commits ............................ [RUN]
[0m22:53:38.531561 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.fact_commits)
[0m22:53:38.532089 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.fact_commits
[0m22:53:38.536447 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m22:53:38.537882 [debug] [Thread-1  ]: Began executing node model.my_pipeline.fact_commits
[0m22:53:38.557992 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m22:53:38.559273 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m22:53:38.559688 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */
create or replace transient table DE_SPEEDRUN.ANALYTICS.fact_commits
         as
        (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.ANALYTICS.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
        );
[0m22:53:38.560032 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:40.356033 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.090 seconds
[0m22:53:40.367286 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: Close
[0m22:53:40.397565 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.836 seconds
[0m22:53:40.410993 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: Close
[0m22:53:40.572685 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c7a5f59f-0692-4330-9867-6445eb4734f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5d42c40>]}
[0m22:53:40.575610 [info ] [Thread-1  ]: 2 of 2 OK created sql table model ANALYTICS.fact_commits ....................... [[32mSUCCESS 1[0m in 2.34s]
[0m22:53:40.577871 [debug] [Thread-1  ]: Finished running node model.my_pipeline.fact_commits
[0m22:53:40.585497 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:53:40.586302 [debug] [MainThread]: Connection 'list_DE_SPEEDRUN' was properly closed.
[0m22:53:40.586890 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was properly closed.
[0m22:53:40.587755 [info ] [MainThread]: 
[0m22:53:40.588535 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 8.89 seconds (8.89s).
[0m22:53:40.590014 [debug] [MainThread]: Command end result
[0m22:53:40.615954 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b5d4a76-8c77-4de2-b72c-581324baa2d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff94c65d00>]}
[0m22:53:40.617427 [info ] [Thread-1  ]: 2 of 2 OK created sql table model ANALYTICS.fact_commits ....................... [[32mSUCCESS 1[0m in 2.08s]
[0m22:53:40.618594 [debug] [Thread-1  ]: Finished running node model.my_pipeline.fact_commits
[0m22:53:40.621914 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:53:40.622512 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was properly closed.
[0m22:53:40.624101 [info ] [MainThread]: 
[0m22:53:40.625122 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 8.92 seconds (8.92s).
[0m22:53:40.626824 [debug] [MainThread]: Command end result
[0m22:53:40.643892 [info ] [MainThread]: 
[0m22:53:40.644905 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:53:40.645269 [info ] [MainThread]: 
[0m22:53:40.645645 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m22:53:40.648994 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.810865, "process_user_time": 5.252254, "process_kernel_time": 3.218651, "process_mem_max_rss": "249648", "process_in_blocks": "12048", "process_out_blocks": "8958"}
[0m22:53:40.649896 [debug] [MainThread]: Command `dbt run` succeeded at 22:53:40.649754 after 12.81 seconds
[0m22:53:40.650433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab524430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa051460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5b1f0a0>]}
[0m22:53:40.650792 [debug] [MainThread]: Flushing usage events
[0m22:53:40.672731 [info ] [MainThread]: 
[0m22:53:40.673222 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:53:40.673527 [info ] [MainThread]: 
[0m22:53:40.673889 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m22:53:40.676014 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.910485, "process_user_time": 5.174032, "process_kernel_time": 3.277478, "process_mem_max_rss": "249144", "process_in_blocks": "8192", "process_out_blocks": "7150"}
[0m22:53:40.676767 [debug] [MainThread]: Command `dbt run` succeeded at 22:53:40.676689 after 12.91 seconds
[0m22:53:40.677309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba0623d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb32630d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb67a3e50>]}
[0m22:53:40.678287 [debug] [MainThread]: Flushing usage events
[0m22:53:44.696264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8fe704c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8dc74a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8dc74fa0>]}
[0m22:53:44.696265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0b18400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaea8aac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaea8ab20>]}


============================== 22:53:44.700446 | 674589e2-9284-4b1b-9aef-4aae4c292f29 ==============================
[0m22:53:44.700446 [info ] [MainThread]: Running with dbt=1.8.7


============================== 22:53:44.700497 | 3db056e0-260f-414f-8672-3ef45259c4c7 ==============================
[0m22:53:44.700497 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:53:44.701145 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m22:53:44.701182 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/.dbt', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:53:45.539080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0870df0>]}
[0m22:53:45.539057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c153d60>]}
[0m22:53:45.577874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8dc7ea00>]}
[0m22:53:45.578969 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m22:53:45.580795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf788550>]}
[0m22:53:45.583299 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m22:53:45.612146 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:53:45.612928 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:53:45.725841 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:53:45.725895 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:53:45.726304 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:53:45.726374 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:53:45.730173 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m22:53:45.730281 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m22:53:45.760038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabdf8340>]}
[0m22:53:45.760456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b153370>]}
[0m22:53:45.932107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabccad00>]}
[0m22:53:45.932194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b022dc0>]}
[0m22:53:45.932619 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m22:53:45.932663 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m22:53:45.933137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c158cd0>]}
[0m22:53:45.933219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8fad1f70>]}
[0m22:53:45.934243 [info ] [MainThread]: 
[0m22:53:45.934252 [info ] [MainThread]: 
[0m22:53:45.934712 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:53:45.934775 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m22:53:45.937760 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m22:53:45.937781 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m22:53:45.948628 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m22:53:45.948684 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m22:53:45.948940 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m22:53:45.948983 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m22:53:45.949199 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:45.949241 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:53:47.316775 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.367 seconds
[0m22:53:47.324463 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m22:53:47.367714 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.417 seconds
[0m22:53:47.379449 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m22:53:47.533690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '674589e2-9284-4b1b-9aef-4aae4c292f29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c18ec10>]}
[0m22:53:47.535345 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:53:47.535879 [info ] [MainThread]: 
[0m22:53:47.560473 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.561117 [info ] [Thread-1  ]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m22:53:47.561967 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m22:53:47.562278 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.589905 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.593248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3db056e0-260f-414f-8672-3ef45259c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ce49be0>]}
[0m22:53:47.595036 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:53:47.608470 [info ] [MainThread]: 
[0m22:53:47.609576 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.635869 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.637393 [info ] [Thread-1  ]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m22:53:47.638708 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m22:53:47.639103 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.661528 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.664103 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.664510 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



      
    ) dbt_internal_test
[0m22:53:47.664887 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:47.674255 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.675919 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:47.694624 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.695827 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m22:53:47.696128 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



      
    ) dbt_internal_test
[0m22:53:47.696447 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:48.569934 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.871 seconds
[0m22:53:48.598801 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: Close
[0m22:53:48.662255 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.997 seconds
[0m22:53:48.679409 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: Close
[0m22:53:49.124734 [info ] [Thread-1  ]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 1.48s]
[0m22:53:49.127850 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:49.130102 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.131916 [info ] [Thread-1  ]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m22:53:49.133201 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m22:53:49.134020 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.145084 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.146538 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.148995 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.150524 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.150856 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



      
    ) dbt_internal_test
[0m22:53:49.151183 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:49.472405 [info ] [Thread-1  ]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 1.90s]
[0m22:53:49.493288 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m22:53:49.502217 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.504772 [info ] [Thread-1  ]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m22:53:49.511109 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m22:53:49.513618 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.523127 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.526058 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:49.532553 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.534038 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m22:53:49.534443 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



      
    ) dbt_internal_test
[0m22:53:49.534838 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:50.222917 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.687 seconds
[0m22:53:50.233497 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: Close
[0m22:53:50.347511 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.195 seconds
[0m22:53:50.365382 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: Close
[0m22:53:50.492918 [info ] [Thread-1  ]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 0.99s]
[0m22:53:50.495163 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:50.496432 [debug] [Thread-1  ]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.497102 [info ] [Thread-1  ]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m22:53:50.497809 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m22:53:50.498328 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.509918 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.512666 [debug] [Thread-1  ]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.515956 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.517762 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.518192 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



      
    ) dbt_internal_test
[0m22:53:50.518631 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:50.577764 [info ] [Thread-1  ]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 1.44s]
[0m22:53:50.579806 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m22:53:50.581108 [debug] [Thread-1  ]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.581728 [info ] [Thread-1  ]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m22:53:50.582253 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m22:53:50.582726 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.591847 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.593080 [debug] [Thread-1  ]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:50.596163 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.597829 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m22:53:50.598227 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



      
    ) dbt_internal_test
[0m22:53:50.598643 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:53:51.610117 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.013 seconds
[0m22:53:51.626877 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m22:53:51.641113 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.124 seconds
[0m22:53:51.647290 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m22:53:51.845168 [info ] [Thread-1  ]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 1.26s]
[0m22:53:51.846291 [debug] [Thread-1  ]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:51.854444 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:53:51.855210 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was properly closed.
[0m22:53:51.855962 [info ] [MainThread]: 
[0m22:53:51.856654 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 5.92 seconds (5.92s).
[0m22:53:51.858206 [debug] [MainThread]: Command end result
[0m22:53:51.876988 [info ] [Thread-1  ]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 1.38s]
[0m22:53:51.879154 [debug] [Thread-1  ]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m22:53:51.882264 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:53:51.882620 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was properly closed.
[0m22:53:51.883065 [info ] [MainThread]: 
[0m22:53:51.883463 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 5.95 seconds (5.95s).
[0m22:53:51.884469 [debug] [MainThread]: Command end result
[0m22:53:51.909920 [info ] [MainThread]: 
[0m22:53:51.910454 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:53:51.910767 [info ] [MainThread]: 
[0m22:53:51.911216 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m22:53:51.914589 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.24708, "process_user_time": 2.830419, "process_kernel_time": 0.468719, "process_mem_max_rss": "210720", "process_in_blocks": "3896", "process_out_blocks": "1823"}
[0m22:53:51.915602 [debug] [MainThread]: Command `dbt test` succeeded at 22:53:51.915506 after 7.25 seconds
[0m22:53:51.916201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0b18400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0766880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf788550>]}
[0m22:53:51.916576 [debug] [MainThread]: Flushing usage events
[0m22:53:51.924469 [info ] [MainThread]: 
[0m22:53:51.925127 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:53:51.925477 [info ] [MainThread]: 
[0m22:53:51.925882 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m22:53:51.928022 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.2606835, "process_user_time": 2.77913, "process_kernel_time": 0.474313, "process_mem_max_rss": "211412", "process_in_blocks": "1576", "process_out_blocks": "1823"}
[0m22:53:51.928783 [debug] [MainThread]: Command `dbt test` succeeded at 22:53:51.928702 after 7.26 seconds
[0m22:53:51.929262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8fe704c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8faa9100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8dc7ea00>]}
[0m22:53:51.929614 [debug] [MainThread]: Flushing usage events
[0m00:00:13.376156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8457e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff83399a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8237efd0>]}


============================== 00:00:13.385484 | daaa5fbf-2892-458d-a24b-8c9c9cad183d ==============================
[0m00:00:13.385484 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:00:13.385986 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:00:14.537559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff608b1d90>]}
[0m00:00:14.564860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82408370>]}
[0m00:00:14.565438 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m00:00:14.590745 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:00:14.694218 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:00:14.694576 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:00:14.698097 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m00:00:14.728101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f861040>]}
[0m00:00:14.837968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60866c70>]}
[0m00:00:14.838327 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m00:00:14.838773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5fab50a0>]}
[0m00:00:14.839596 [info ] [MainThread]: 
[0m00:00:14.840119 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m00:00:14.843738 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m00:00:14.852259 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m00:00:14.852520 [debug] [ThreadPool]: On list_DE_SPEEDRUN: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
show terse schemas in database DE_SPEEDRUN
    limit 10000
[0m00:00:14.852788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:16.503211 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.647 seconds
[0m00:00:16.513067 [debug] [ThreadPool]: On list_DE_SPEEDRUN: Close
[0m00:00:16.976576 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN, now list_DE_SPEEDRUN_ANALYTICS)
[0m00:00:17.076063 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m00:00:17.077348 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m00:00:17.077825 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:18.458762 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.380 seconds
[0m00:00:18.469072 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m00:00:18.719270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84592f40>]}
[0m00:00:18.722532 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:18.726728 [info ] [MainThread]: 
[0m00:00:18.751250 [debug] [Thread-1  ]: Began running node model.my_pipeline.stg_commits
[0m00:00:18.753039 [info ] [Thread-1  ]: 1 of 2 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m00:00:18.754854 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.stg_commits)
[0m00:00:18.755536 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.stg_commits
[0m00:00:18.775746 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m00:00:18.778803 [debug] [Thread-1  ]: Began executing node model.my_pipeline.stg_commits
[0m00:00:18.807536 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m00:00:18.809605 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m00:00:18.810029 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */
create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
   as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  );
[0m00:00:18.810389 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:00:19.671488 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.860 seconds
[0m00:00:19.714282 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: Close
[0m00:00:19.929948 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84592f40>]}
[0m00:00:19.931675 [info ] [Thread-1  ]: 1 of 2 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 1.17s]
[0m00:00:19.933258 [debug] [Thread-1  ]: Finished running node model.my_pipeline.stg_commits
[0m00:00:19.934833 [debug] [Thread-1  ]: Began running node model.my_pipeline.fact_commits
[0m00:00:19.935257 [info ] [Thread-1  ]: 2 of 2 START sql table model ANALYTICS.fact_commits ............................ [RUN]
[0m00:00:19.935867 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.fact_commits)
[0m00:00:19.936180 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.fact_commits
[0m00:00:19.939151 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m00:00:19.940059 [debug] [Thread-1  ]: Began executing node model.my_pipeline.fact_commits
[0m00:00:19.956417 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m00:00:19.957589 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m00:00:19.957885 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */
create or replace transient table DE_SPEEDRUN.ANALYTICS.fact_commits
         as
        (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.ANALYTICS.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
        );
[0m00:00:19.958176 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:00:22.355772 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.395 seconds
[0m00:00:22.382514 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: Close
[0m00:00:22.585346 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'daaa5fbf-2892-458d-a24b-8c9c9cad183d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84592f40>]}
[0m00:00:22.588839 [info ] [Thread-1  ]: 2 of 2 OK created sql table model ANALYTICS.fact_commits ....................... [[32mSUCCESS 1[0m in 2.65s]
[0m00:00:22.594805 [debug] [Thread-1  ]: Finished running node model.my_pipeline.fact_commits
[0m00:00:22.603285 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:00:22.604156 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was properly closed.
[0m00:00:22.605474 [info ] [MainThread]: 
[0m00:00:22.606432 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 7.76 seconds (7.76s).
[0m00:00:22.608409 [debug] [MainThread]: Command end result
[0m00:00:22.692045 [info ] [MainThread]: 
[0m00:00:22.693100 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:00:22.693855 [info ] [MainThread]: 
[0m00:00:22.695263 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m00:00:22.699034 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.3572235, "process_user_time": 3.190503, "process_kernel_time": 1.268904, "process_mem_max_rss": "202892", "process_out_blocks": "1820", "process_in_blocks": "0"}
[0m00:00:22.700084 [debug] [MainThread]: Command `dbt run` succeeded at 00:00:22.700004 after 9.36 seconds
[0m00:00:22.700613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8457e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff841c3fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82408370>]}
[0m00:00:22.700897 [debug] [MainThread]: Flushing usage events
[0m00:00:26.044785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92274430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff900d2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90113820>]}


============================== 00:00:26.048481 | f9b5a62a-f395-4d6c-a8cb-18eb9a408134 ==============================
[0m00:00:26.048481 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:00:26.051046 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/.dbt', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:00:26.669900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff900f32e0>]}
[0m00:00:26.695945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7472cc40>]}
[0m00:00:26.696459 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m00:00:26.719898 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:00:26.809157 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:00:26.809537 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:00:26.813125 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m00:00:26.840954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d5b0df0>]}
[0m00:00:26.957314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d484760>]}
[0m00:00:26.957713 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m00:00:26.958143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff746a1280>]}
[0m00:00:26.959074 [info ] [MainThread]: 
[0m00:00:26.959494 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m00:00:26.962453 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m00:00:26.973464 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m00:00:26.973754 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m00:00:26.974013 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:28.346842 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.372 seconds
[0m00:00:28.354663 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m00:00:29.078740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9b5a62a-f395-4d6c-a8cb-18eb9a408134', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff74789ac0>]}
[0m00:00:29.080413 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:29.081039 [info ] [MainThread]: 
[0m00:00:29.096656 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:00:29.097201 [info ] [Thread-1  ]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m00:00:29.097746 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m00:00:29.098081 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:00:29.112998 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:00:29.115373 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:00:29.127555 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:00:29.129000 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:00:29.129347 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



      
    ) dbt_internal_test
[0m00:00:29.129637 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:00:30.186082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.055 seconds
[0m00:00:30.215204 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: Close
[0m00:00:30.422993 [info ] [Thread-1  ]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 1.32s]
[0m00:00:30.427172 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:00:30.429314 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:00:30.435808 [info ] [Thread-1  ]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m00:00:30.439627 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m00:00:30.441177 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:00:30.450224 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:00:30.451572 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:00:30.454564 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:00:30.456010 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:00:30.456414 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



      
    ) dbt_internal_test
[0m00:00:30.457042 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:00:31.902878 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.445 seconds
[0m00:00:31.912981 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: Close
[0m00:00:32.415342 [info ] [Thread-1  ]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 1.98s]
[0m00:00:32.421105 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:00:32.422975 [debug] [Thread-1  ]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:00:32.424538 [info ] [Thread-1  ]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m00:00:32.425774 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m00:00:32.426489 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:00:32.439666 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:00:32.441374 [debug] [Thread-1  ]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:00:32.444500 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:00:32.446355 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:00:32.446795 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



      
    ) dbt_internal_test
[0m00:00:32.447199 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:00:33.237766 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.790 seconds
[0m00:00:33.243464 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m00:00:33.449899 [info ] [Thread-1  ]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 1.02s]
[0m00:00:33.452632 [debug] [Thread-1  ]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:00:33.458025 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:00:33.458987 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was properly closed.
[0m00:00:33.459983 [info ] [MainThread]: 
[0m00:00:33.461452 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 6.50 seconds (6.50s).
[0m00:00:33.463487 [debug] [MainThread]: Command end result
[0m00:00:33.519046 [info ] [MainThread]: 
[0m00:00:33.519754 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:00:33.520090 [info ] [MainThread]: 
[0m00:00:33.520454 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:00:33.523481 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.5080075, "process_user_time": 2.960871, "process_kernel_time": 0.50107, "process_mem_max_rss": "203080", "process_out_blocks": "1823", "process_in_blocks": "0"}
[0m00:00:33.524496 [debug] [MainThread]: Command `dbt test` succeeded at 00:00:33.524391 after 7.51 seconds
[0m00:00:33.525192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92274430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91e8f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91ee7130>]}
[0m00:00:33.525582 [debug] [MainThread]: Flushing usage events
[0m00:43:28.278766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3d783d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2950ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2950fa0>]}


============================== 00:43:28.338504 | dca81103-1428-470f-9c67-64e8f7a42264 ==============================
[0m00:43:28.338504 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:43:28.341822 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m00:43:32.587947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9002a490>]}
[0m00:43:32.637227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90082f10>]}
[0m00:43:32.641233 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m00:43:32.708359 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:43:33.073076 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:43:33.073715 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:43:33.081712 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m00:43:33.115280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf077fa0>]}
[0m00:43:33.338426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f38f730>]}
[0m00:43:33.338960 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m00:43:33.339433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f2b64f0>]}
[0m00:43:33.340381 [info ] [MainThread]: 
[0m00:43:33.340949 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m00:43:33.344375 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m00:43:33.359682 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m00:43:33.360064 [debug] [ThreadPool]: On list_DE_SPEEDRUN: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
show terse schemas in database DE_SPEEDRUN
    limit 10000
[0m00:43:33.360334 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:34.994435 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.633 seconds
[0m00:43:35.001235 [debug] [ThreadPool]: On list_DE_SPEEDRUN: Close
[0m00:43:35.215219 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN, now list_DE_SPEEDRUN_ANALYTICS)
[0m00:43:35.229286 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m00:43:35.229651 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m00:43:35.229930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:43:35.977920 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.748 seconds
[0m00:43:35.979616 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m00:43:36.193417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90060b80>]}
[0m00:43:36.194467 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:36.197682 [info ] [MainThread]: 
[0m00:43:36.207930 [debug] [Thread-1  ]: Began running node model.my_pipeline.stg_commits
[0m00:43:36.208613 [info ] [Thread-1  ]: 1 of 2 START sql view model ANALYTICS.stg_commits .............................. [RUN]
[0m00:43:36.209117 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now model.my_pipeline.stg_commits)
[0m00:43:36.209422 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.stg_commits
[0m00:43:36.214942 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m00:43:36.217572 [debug] [Thread-1  ]: Began executing node model.my_pipeline.stg_commits
[0m00:43:36.240226 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m00:43:36.242889 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m00:43:36.243218 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */
create or replace   view DE_SPEEDRUN.ANALYTICS.stg_commits
  
   as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  );
[0m00:43:36.243525 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:36.939309 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.696 seconds
[0m00:43:36.953902 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: Close
[0m00:43:37.156379 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f38f790>]}
[0m00:43:37.157008 [info ] [Thread-1  ]: 1 of 2 OK created sql view model ANALYTICS.stg_commits ......................... [[32mSUCCESS 1[0m in 0.95s]
[0m00:43:37.157699 [debug] [Thread-1  ]: Finished running node model.my_pipeline.stg_commits
[0m00:43:37.158609 [debug] [Thread-1  ]: Began running node model.my_pipeline.fact_commits
[0m00:43:37.158987 [info ] [Thread-1  ]: 2 of 2 START sql table model ANALYTICS.fact_commits ............................ [RUN]
[0m00:43:37.159379 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.fact_commits)
[0m00:43:37.159658 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.fact_commits
[0m00:43:37.161906 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m00:43:37.164835 [debug] [Thread-1  ]: Began executing node model.my_pipeline.fact_commits
[0m00:43:37.178477 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m00:43:37.179533 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m00:43:37.179842 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */
create or replace transient table DE_SPEEDRUN.ANALYTICS.fact_commits
         as
        (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.ANALYTICS.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
        );
[0m00:43:37.180155 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:39.887145 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.706 seconds
[0m00:43:39.897397 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: Close
[0m00:43:40.104782 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dca81103-1428-470f-9c67-64e8f7a42264', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaea89f70>]}
[0m00:43:40.106235 [info ] [Thread-1  ]: 2 of 2 OK created sql table model ANALYTICS.fact_commits ....................... [[32mSUCCESS 1[0m in 2.94s]
[0m00:43:40.107203 [debug] [Thread-1  ]: Finished running node model.my_pipeline.fact_commits
[0m00:43:40.110505 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:40.110825 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was properly closed.
[0m00:43:40.111141 [info ] [MainThread]: 
[0m00:43:40.111517 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 6.77 seconds (6.77s).
[0m00:43:40.112486 [debug] [MainThread]: Command end result
[0m00:43:40.163132 [info ] [MainThread]: 
[0m00:43:40.163820 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:43:40.164184 [info ] [MainThread]: 
[0m00:43:40.164683 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m00:43:40.169292 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.963564, "process_user_time": 5.09054, "process_kernel_time": 6.020094, "process_mem_max_rss": "209428", "process_out_blocks": "1820", "process_in_blocks": "0"}
[0m00:43:40.170103 [debug] [MainThread]: Command `dbt run` succeeded at 00:43:40.170019 after 11.96 seconds
[0m00:43:40.170503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3d783d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9006b2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9002a490>]}
[0m00:43:40.170799 [debug] [MainThread]: Flushing usage events
[0m00:43:42.932828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff970502b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97e77dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff953ecb80>]}


============================== 00:43:42.936389 | 68428b9e-bf07-4796-919f-fb52fa36182a ==============================
[0m00:43:42.936389 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:43:42.937678 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/.dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:43:43.635660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7957a310>]}
[0m00:43:43.662707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95692760>]}
[0m00:43:43.663298 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m00:43:43.681233 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:43:43.779465 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:43:43.779960 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:43:43.783489 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_pipeline.example
[0m00:43:43.813900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92334040>]}
[0m00:43:43.946483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92202df0>]}
[0m00:43:43.946926 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m00:43:43.947426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff923cd3a0>]}
[0m00:43:43.949229 [info ] [MainThread]: 
[0m00:43:43.950184 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m00:43:43.955319 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_ANALYTICS'
[0m00:43:43.967139 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_ANALYTICS"
[0m00:43:43.967489 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_ANALYTICS"} */
show objects in DE_SPEEDRUN.ANALYTICS limit 10000
[0m00:43:43.967793 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:43:45.147269 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.179 seconds
[0m00:43:45.155072 [debug] [ThreadPool]: On list_DE_SPEEDRUN_ANALYTICS: Close
[0m00:43:45.357044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68428b9e-bf07-4796-919f-fb52fa36182a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79560c40>]}
[0m00:43:45.363072 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:45.364355 [info ] [MainThread]: 
[0m00:43:45.393650 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:43:45.394274 [info ] [Thread-1  ]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m00:43:45.394996 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_ANALYTICS, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m00:43:45.395363 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:43:45.414110 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:43:45.421975 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:43:45.444998 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:43:45.447224 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m00:43:45.447686 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select author_name
from DE_SPEEDRUN.ANALYTICS.fact_commits
where author_name is null



      
    ) dbt_internal_test
[0m00:43:45.448262 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:48.064519 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.615 seconds
[0m00:43:48.119727 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: Close
[0m00:43:48.337787 [info ] [Thread-1  ]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 2.94s]
[0m00:43:48.342111 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m00:43:48.344177 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:43:48.348220 [info ] [Thread-1  ]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m00:43:48.350161 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m00:43:48.351230 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:43:48.362724 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:43:48.364694 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:43:48.368097 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:43:48.369655 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m00:43:48.370078 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select commit_hash
from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is null



      
    ) dbt_internal_test
[0m00:43:48.370505 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:48.987997 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.617 seconds
[0m00:43:48.993604 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: Close
[0m00:43:49.229508 [info ] [Thread-1  ]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 0.88s]
[0m00:43:49.231446 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m00:43:49.232790 [debug] [Thread-1  ]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:43:49.233308 [info ] [Thread-1  ]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m00:43:49.233830 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m00:43:49.234181 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:43:49.239628 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:43:49.240720 [debug] [Thread-1  ]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:43:49.245438 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:43:49.246977 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m00:43:49.247348 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.ANALYTICS.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



      
    ) dbt_internal_test
[0m00:43:49.247650 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:43:50.351578 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.103 seconds
[0m00:43:50.388563 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m00:43:50.587372 [info ] [Thread-1  ]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 1.35s]
[0m00:43:50.588781 [debug] [Thread-1  ]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m00:43:50.593177 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:50.593733 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was properly closed.
[0m00:43:50.594315 [info ] [MainThread]: 
[0m00:43:50.594742 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 6.64 seconds (6.64s).
[0m00:43:50.595911 [debug] [MainThread]: Command end result
[0m00:43:50.644163 [info ] [MainThread]: 
[0m00:43:50.645064 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:43:50.645424 [info ] [MainThread]: 
[0m00:43:50.646028 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:43:50.656637 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.750352, "process_user_time": 2.747186, "process_kernel_time": 0.550445, "process_mem_max_rss": "211456", "process_out_blocks": "1823", "process_in_blocks": "0"}
[0m00:43:50.657515 [debug] [MainThread]: Command `dbt test` succeeded at 00:43:50.657415 after 7.75 seconds
[0m00:43:50.658997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff970502b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96c1d040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95692760>]}
[0m00:43:50.659422 [debug] [MainThread]: Flushing usage events
[0m19:10:45.543961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaec27550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad1943a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac10c1f0>]}


============================== 19:10:45.555514 | ef98b186-cdec-488d-bc59-c33a42a1f0fd ==============================
[0m19:10:45.555514 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:10:45.556306 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:10:45.557444 [error] [MainThread]: Encountered an error:
Runtime Error
  dbt_project.yml does not parse to a dictionary
[0m19:10:45.558673 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.051443584, "process_user_time": 1.136969, "process_kernel_time": 0.788137, "process_mem_max_rss": "117928", "process_in_blocks": "9432", "process_out_blocks": "1682", "command_success": false}
[0m19:10:45.559213 [debug] [MainThread]: Command `dbt run` failed at 19:10:45.559140 after 0.05 seconds
[0m19:10:45.559741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaec27550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffac117460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4b3b20>]}
[0m19:10:45.559995 [debug] [MainThread]: Flushing usage events
[0m19:10:49.244014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb52c73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb30c7b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb30c76a0>]}


============================== 19:10:49.247599 | b26d3e6a-f973-46f5-a671-cfea6b1545ff ==============================
[0m19:10:49.247599 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:10:49.248056 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '.', 'log_path': 'logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir .', 'send_anonymous_usage_stats': 'True'}
[0m19:10:49.248554 [error] [MainThread]: Encountered an error:
Runtime Error
  dbt_project.yml does not parse to a dictionary
[0m19:10:49.249056 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.034277294, "process_user_time": 0.876558, "process_kernel_time": 0.125936, "process_mem_max_rss": "117984", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:10:49.249502 [debug] [MainThread]: Command `dbt run` failed at 19:10:49.249451 after 0.03 seconds
[0m19:10:49.249742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb52c73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb37afbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb30c7b80>]}
[0m19:10:49.249986 [debug] [MainThread]: Flushing usage events
[0m19:12:25.551806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b3632b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a591520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a591f70>]}


============================== 19:12:25.556644 | 35fe5c03-b497-4546-845c-c5c3a7883059 ==============================
[0m19:12:25.556644 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:12:25.557164 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:12:25.560442 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:12:25.561211 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.044594876, "process_user_time": 0.901365, "process_kernel_time": 0.320395, "process_mem_max_rss": "117628", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:12:25.561627 [debug] [MainThread]: Command `dbt run` failed at 19:12:25.561574 after 0.05 seconds
[0m19:12:25.561843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b3632b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98fdfa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98fdfa60>]}
[0m19:12:25.562060 [debug] [MainThread]: Flushing usage events
[0m19:12:29.685441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb412a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb20ce5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb20ceb20>]}


============================== 19:12:29.689918 | 3677c356-10fd-4a21-b7f3-9d7055033833 ==============================
[0m19:12:29.689918 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:12:29.690371 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:12:29.695831 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:12:29.696908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.042285666, "process_user_time": 1.531764, "process_kernel_time": 0.261998, "process_mem_max_rss": "117936", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:12:29.697398 [debug] [MainThread]: Command `dbt run` failed at 19:12:29.697334 after 0.04 seconds
[0m19:12:29.697668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb412a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1e929d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1e92a30>]}
[0m19:12:29.697958 [debug] [MainThread]: Flushing usage events
[0m19:16:26.257427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84da73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8334e400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82bac7c0>]}


============================== 19:16:26.261146 | f8120c93-6cb8-4a1e-9d52-a9a7ca06094b ==============================
[0m19:16:26.261146 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:16:26.261558 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '.', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir .', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:16:26.264627 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:16:26.265393 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.0456025, "process_user_time": 0.865654, "process_kernel_time": 0.125968, "process_mem_max_rss": "117964", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:16:26.265742 [debug] [MainThread]: Command `dbt run` failed at 19:16:26.265681 after 0.05 seconds
[0m19:16:26.265997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84da73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82ae09a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82ae0a00>]}
[0m19:16:26.266251 [debug] [MainThread]: Flushing usage events
[0m19:17:32.855253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9007400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6e24c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6e24fa0>]}


============================== 19:17:32.858734 | 91b322ab-c716-4f68-b65f-c5e966220b1f ==============================
[0m19:17:32.858734 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:17:32.859233 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir .', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:17:32.862021 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:17:32.862685 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.035109624, "process_user_time": 0.838093, "process_kernel_time": 0.113012, "process_mem_max_rss": "117772", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:17:32.863028 [debug] [MainThread]: Command `dbt run` failed at 19:17:32.862965 after 0.04 seconds
[0m19:17:32.863270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9007400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6d5aa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6d5aa60>]}
[0m19:17:32.863513 [debug] [MainThread]: Flushing usage events
[0m19:18:40.320279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa600c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3f805b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3f80b20>]}


============================== 19:18:40.324271 | 347d2f13-d9ba-4497-b645-5da3e761893e ==============================
[0m19:18:40.324271 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:18:40.324843 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:18:40.328016 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:18:40.328605 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.038718708, "process_user_time": 0.849534, "process_kernel_time": 0.114206, "process_mem_max_rss": "117940", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:18:40.329068 [debug] [MainThread]: Command `dbt run` failed at 19:18:40.329014 after 0.04 seconds
[0m19:18:40.329324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa600c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3d459d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3d45a30>]}
[0m19:18:40.329556 [debug] [MainThread]: Flushing usage events
[0m19:19:17.205323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3ed04c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1d14c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1d14fa0>]}


============================== 19:19:17.209355 | ef9892a0-d917-4088-95b6-1449de0a1090 ==============================
[0m19:19:17.209355 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:19:17.209742 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '.', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir .', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:19:17.212413 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'SNOWFLAKE_ACCOUNT'
[0m19:19:17.213058 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.034420874, "process_user_time": 0.815855, "process_kernel_time": 0.137312, "process_mem_max_rss": "118308", "process_out_blocks": "2", "command_success": false, "process_in_blocks": "0"}
[0m19:19:17.213386 [debug] [MainThread]: Command `dbt run` failed at 19:19:17.213336 after 0.03 seconds
[0m19:19:17.213615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3ed04c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1b8ba00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1b8ba60>]}
[0m19:19:17.213823 [debug] [MainThread]: Flushing usage events
[0m19:27:30.217625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa14df250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f987af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f987ca0>]}


============================== 19:27:30.223494 | de4528d2-17c2-4a21-a70d-25758b645f16 ==============================
[0m19:27:30.223494 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:27:30.224168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '.', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir .', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:27:31.290842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8408e730>]}
[0m19:27:31.319541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d718e20>]}
[0m19:27:31.320216 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m19:27:31.338701 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:27:31.413130 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m19:27:31.413557 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:27:31.413921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa00f14c0>]}
[0m19:27:32.106558 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m19:27:32.107379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d746c40>]}
[0m19:27:32.252664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9bca49a0>]}
[0m19:27:32.325219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9bbed5b0>]}
[0m19:27:32.325599 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m19:27:32.326155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9bc011f0>]}
[0m19:27:32.326944 [info ] [MainThread]: 
[0m19:27:32.327426 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:27:32.330311 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN'
[0m19:27:32.338065 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN"
[0m19:27:32.338348 [debug] [ThreadPool]: On list_DE_SPEEDRUN: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN"} */
show terse schemas in database DE_SPEEDRUN
    limit 10000
[0m19:27:32.338595 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:27:34.924670 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 2.585 seconds
[0m19:27:34.932560 [debug] [ThreadPool]: On list_DE_SPEEDRUN: Close
[0m19:27:35.180397 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_PUBLIC'
[0m19:27:35.198372 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_PUBLIC"
[0m19:27:35.198948 [debug] [ThreadPool]: On list_DE_SPEEDRUN_PUBLIC: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_PUBLIC"} */
show objects in DE_SPEEDRUN.PUBLIC limit 10000
[0m19:27:35.199548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:27:36.615390 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.414 seconds
[0m19:27:36.628358 [debug] [ThreadPool]: On list_DE_SPEEDRUN_PUBLIC: Close
[0m19:27:36.885782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9bd91640>]}
[0m19:27:36.889093 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:27:36.892328 [info ] [MainThread]: 
[0m19:27:36.926469 [debug] [Thread-1  ]: Began running node model.my_pipeline.stg_commits
[0m19:27:36.928418 [info ] [Thread-1  ]: 1 of 2 START sql view model PUBLIC.stg_commits ................................. [RUN]
[0m19:27:36.929434 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_PUBLIC, now model.my_pipeline.stg_commits)
[0m19:27:36.929853 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.stg_commits
[0m19:27:36.960201 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.stg_commits"
[0m19:27:36.965357 [debug] [Thread-1  ]: Began executing node model.my_pipeline.stg_commits
[0m19:27:37.007492 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.stg_commits"
[0m19:27:37.013531 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.stg_commits"
[0m19:27:37.014360 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.stg_commits"} */
create or replace   view DE_SPEEDRUN.PUBLIC.stg_commits
  
   as (
    WITH raw_source AS (
    SELECT * FROM DE_SPEEDRUN.RAW.RAW_COMMITS
),

parsed_data AS (
    SELECT
        -- Parse the JSON (Snowflake syntax)
        raw_data:sha::STRING as commit_hash,
        raw_data:commit:author:name::STRING as author_name,
        raw_data:commit:author:date::TIMESTAMP as commit_at,
        raw_data:commit:message::STRING as commit_message,
        raw_data:html_url::STRING as commit_url,
        ingested_at
    FROM raw_source
)

SELECT * FROM parsed_data
  );
[0m19:27:37.015321 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:27:38.905907 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.890 seconds
[0m19:27:38.929487 [debug] [Thread-1  ]: On model.my_pipeline.stg_commits: Close
[0m19:27:39.899191 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff844fff70>]}
[0m19:27:39.902167 [info ] [Thread-1  ]: 1 of 2 OK created sql view model PUBLIC.stg_commits ............................ [[32mSUCCESS 1[0m in 2.96s]
[0m19:27:39.903198 [debug] [Thread-1  ]: Finished running node model.my_pipeline.stg_commits
[0m19:27:39.908631 [debug] [Thread-1  ]: Began running node model.my_pipeline.fact_commits
[0m19:27:39.909150 [info ] [Thread-1  ]: 2 of 2 START sql table model PUBLIC.fact_commits ............................... [RUN]
[0m19:27:39.909732 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly model.my_pipeline.stg_commits, now model.my_pipeline.fact_commits)
[0m19:27:39.910066 [debug] [Thread-1  ]: Began compiling node model.my_pipeline.fact_commits
[0m19:27:39.915771 [debug] [Thread-1  ]: Writing injected SQL for node "model.my_pipeline.fact_commits"
[0m19:27:39.916750 [debug] [Thread-1  ]: Began executing node model.my_pipeline.fact_commits
[0m19:27:39.933099 [debug] [Thread-1  ]: Writing runtime sql for node "model.my_pipeline.fact_commits"
[0m19:27:39.934833 [debug] [Thread-1  ]: Using snowflake connection "model.my_pipeline.fact_commits"
[0m19:27:39.935125 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "model.my_pipeline.fact_commits"} */
create or replace transient table DE_SPEEDRUN.PUBLIC.fact_commits
         as
        (

SELECT
    commit_hash,
    author_name,
    commit_message,
    commit_at,
    commit_url,
    -- Simple transformation: extract just the date for daily reporting
    TO_DATE(commit_at) as commit_date
FROM DE_SPEEDRUN.PUBLIC.stg_commits
-- We use ref() so dbt knows to run stg_commits first!
        );
[0m19:27:39.935432 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:27:43.302940 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 3.365 seconds
[0m19:27:43.315371 [debug] [Thread-1  ]: On model.my_pipeline.fact_commits: Close
[0m19:27:43.574040 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de4528d2-17c2-4a21-a70d-25758b645f16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7c63e940>]}
[0m19:27:43.575986 [info ] [Thread-1  ]: 2 of 2 OK created sql table model PUBLIC.fact_commits .......................... [[32mSUCCESS 1[0m in 3.66s]
[0m19:27:43.578688 [debug] [Thread-1  ]: Finished running node model.my_pipeline.fact_commits
[0m19:27:43.583697 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:27:43.584341 [debug] [MainThread]: Connection 'list_DE_SPEEDRUN' was properly closed.
[0m19:27:43.584849 [debug] [MainThread]: Connection 'model.my_pipeline.fact_commits' was properly closed.
[0m19:27:43.585511 [info ] [MainThread]: 
[0m19:27:43.586277 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 11.26 seconds (11.26s).
[0m19:27:43.588076 [debug] [MainThread]: Command end result
[0m19:27:43.637661 [info ] [MainThread]: 
[0m19:27:43.638312 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:27:43.638688 [info ] [MainThread]: 
[0m19:27:43.639097 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:27:43.642235 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.46341, "process_user_time": 4.032616, "process_kernel_time": 0.927269, "process_mem_max_rss": "250508", "process_in_blocks": "10056", "process_out_blocks": "7326"}
[0m19:27:43.643027 [debug] [MainThread]: Command `dbt run` succeeded at 19:27:43.642945 after 13.46 seconds
[0m19:27:43.643443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa14df250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa00f15b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d6c2040>]}
[0m19:27:43.643712 [debug] [MainThread]: Flushing usage events
[0m19:27:47.009138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadad5280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabf81af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffabf81ca0>]}


============================== 19:27:47.013226 | 22b0d58b-9a42-427d-816b-c845984dc01a ==============================
[0m19:27:47.013226 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:27:47.014110 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/transform/my_pipeline/logs', 'fail_fast': 'False', 'profiles_dir': '.', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir .', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:27:47.491178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90697730>]}
[0m19:27:47.516925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9019fe20>]}
[0m19:27:47.517393 [info ] [MainThread]: Registered adapter: snowflake=1.8.4
[0m19:27:47.540698 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:27:47.622209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:27:47.622538 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:27:47.650774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8e3d610>]}
[0m19:27:47.759774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9065b040>]}
[0m19:27:47.760172 [info ] [MainThread]: Found 2 models, 3 data tests, 1 source, 454 macros
[0m19:27:47.760612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad696130>]}
[0m19:27:47.761449 [info ] [MainThread]: 
[0m19:27:47.761904 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:27:47.764847 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_DE_SPEEDRUN_PUBLIC'
[0m19:27:47.775785 [debug] [ThreadPool]: Using snowflake connection "list_DE_SPEEDRUN_PUBLIC"
[0m19:27:47.776145 [debug] [ThreadPool]: On list_DE_SPEEDRUN_PUBLIC: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "connection_name": "list_DE_SPEEDRUN_PUBLIC"} */
show objects in DE_SPEEDRUN.PUBLIC limit 10000
[0m19:27:47.776404 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:27:49.505756 [debug] [ThreadPool]: SQL status: SUCCESS 2 in 1.729 seconds
[0m19:27:49.510872 [debug] [ThreadPool]: On list_DE_SPEEDRUN_PUBLIC: Close
[0m19:27:49.749885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22b0d58b-9a42-427d-816b-c845984dc01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9067bfa0>]}
[0m19:27:49.751736 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:27:49.753731 [info ] [MainThread]: 
[0m19:27:49.768329 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m19:27:49.769170 [info ] [Thread-1  ]: 1 of 3 START test not_null_fact_commits_author_name ............................ [RUN]
[0m19:27:49.770004 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_DE_SPEEDRUN_PUBLIC, now test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb)
[0m19:27:49.770617 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m19:27:49.790847 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m19:27:49.792470 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m19:27:49.807917 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m19:27:49.809362 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"
[0m19:27:49.809685 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select author_name
from DE_SPEEDRUN.PUBLIC.fact_commits
where author_name is null



      
    ) dbt_internal_test
[0m19:27:49.810014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:27:50.782842 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.973 seconds
[0m19:27:50.812785 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb: Close
[0m19:27:51.068502 [info ] [Thread-1  ]: 1 of 3 PASS not_null_fact_commits_author_name .................................. [[32mPASS[0m in 1.30s]
[0m19:27:51.071143 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb
[0m19:27:51.072668 [debug] [Thread-1  ]: Began running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m19:27:51.075073 [info ] [Thread-1  ]: 2 of 3 START test not_null_fact_commits_commit_hash ............................ [RUN]
[0m19:27:51.079511 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_author_name.fb94aec9cb, now test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62)
[0m19:27:51.081058 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m19:27:51.088063 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m19:27:51.089948 [debug] [Thread-1  ]: Began executing node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m19:27:51.093195 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m19:27:51.094609 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"
[0m19:27:51.095133 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select commit_hash
from DE_SPEEDRUN.PUBLIC.fact_commits
where commit_hash is null



      
    ) dbt_internal_test
[0m19:27:51.095618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:27:52.944826 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.847 seconds
[0m19:27:52.957119 [debug] [Thread-1  ]: On test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62: Close
[0m19:27:53.211996 [info ] [Thread-1  ]: 2 of 3 PASS not_null_fact_commits_commit_hash .................................. [[32mPASS[0m in 2.13s]
[0m19:27:53.215926 [debug] [Thread-1  ]: Finished running node test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62
[0m19:27:53.221262 [debug] [Thread-1  ]: Began running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m19:27:53.225064 [info ] [Thread-1  ]: 3 of 3 START test unique_fact_commits_commit_hash .............................. [RUN]
[0m19:27:53.225643 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly test.my_pipeline.not_null_fact_commits_commit_hash.80258cee62, now test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745)
[0m19:27:53.226606 [debug] [Thread-1  ]: Began compiling node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m19:27:53.237517 [debug] [Thread-1  ]: Writing injected SQL for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m19:27:53.239760 [debug] [Thread-1  ]: Began executing node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m19:27:53.242686 [debug] [Thread-1  ]: Writing runtime sql for node "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m19:27:53.244840 [debug] [Thread-1  ]: Using snowflake connection "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"
[0m19:27:53.245433 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "my_pipeline", "target_name": "dev", "node_id": "test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    commit_hash as unique_field,
    count(*) as n_records

from DE_SPEEDRUN.PUBLIC.fact_commits
where commit_hash is not null
group by commit_hash
having count(*) > 1



      
    ) dbt_internal_test
[0m19:27:53.245958 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:27:55.126889 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.880 seconds
[0m19:27:55.142504 [debug] [Thread-1  ]: On test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745: Close
[0m19:27:55.342702 [info ] [Thread-1  ]: 3 of 3 PASS unique_fact_commits_commit_hash .................................... [[32mPASS[0m in 2.12s]
[0m19:27:55.347283 [debug] [Thread-1  ]: Finished running node test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745
[0m19:27:55.357297 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:27:55.357993 [debug] [MainThread]: Connection 'test.my_pipeline.unique_fact_commits_commit_hash.87f8e48745' was properly closed.
[0m19:27:55.358860 [info ] [MainThread]: 
[0m19:27:55.359706 [info ] [MainThread]: Finished running 3 data tests in 0 hours 0 minutes and 7.60 seconds (7.60s).
[0m19:27:55.361750 [debug] [MainThread]: Command end result
[0m19:27:55.409338 [info ] [MainThread]: 
[0m19:27:55.409997 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:27:55.410370 [info ] [MainThread]: 
[0m19:27:55.410772 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m19:27:55.413434 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 8.433125, "process_user_time": 2.682809, "process_kernel_time": 0.267372, "process_mem_max_rss": "211160", "process_in_blocks": "2296", "process_out_blocks": "1823"}
[0m19:27:55.417106 [debug] [MainThread]: Command `dbt test` succeeded at 19:27:55.417035 after 8.44 seconds
[0m19:27:55.417707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadad5280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9019fe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad6f3130>]}
[0m19:27:55.418138 [debug] [MainThread]: Flushing usage events
